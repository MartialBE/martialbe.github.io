{"pages":[{"title":"404","text":"爆炸,页面炸没了！","link":"/404.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"search","text":"","link":"/search/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"动物森友会开启复活节活动","text":"动物森友会的复活节活动开始了，由于没有联网，导致复活节无法开启。所以记录一下如何开启复活节活动。游戏版本： 1.1.1 - 1.1.2 (1.1.3 未升级，不知道能否支持，理论上应该没问题)。 JKSV下载首先下载jksv.nro 用于备份和导入使用.下载后，在相册中打开。选择BCAT,找到动物森林，选择new 随便命名，创建一个备份。 存档下载然后下载 存档 (Google Drive) 拿出SD卡，或者通过nxmtp在电脑中浏览SD卡目录，找到JKSV目录，然后进去Animal Crossing New Horizons，找到你创建的备份文件夹。打开文件夹， 将里面除了passphrase.bin以外的文件/目录都删除。解压上面的存档， 将directories文件夹复制到JKSV的存档目录里面。 恢复存档重新打开 jksv.nro，选择BCAT(不要选择device，否则会被删除存档),找到动物森林。选择你的备份，按Y键恢复。 打开游戏看到版本号有一个a字说明成功了。","link":"/post/Animal-Crossing-ban/"},{"title":"GoogleMap国内反代配置","text":"由于公司海外和国内业务的需求，需要使用到谷歌服务，因为不可描述的原因，谷歌在国内一直处于404状态。所以本文记录一下针对谷歌地图服务反代的配置操作。 原理介绍谷歌地图 javascript 的调用是通过引入一个入口js文件 https://maps.googleapis.com/maps/api/js，然后加载所有谷歌地图所需要的资源链接。但是这个入口js文件中还存在很多谷歌的资源链接， 所以只反代入口js文件，事实上还是无法去正常加载 地图资源。 所以如果想要能在国内正常使用谷歌地图，则需要将该入口js 文件中所有的 资源链接都进行反代。 配置流程： 一台可以访问Google Map的服务器，并且未被墙； 提取入口js文件中的资源链接地址； 编写Nginx配置文件，对反代过来的文件中的地址进行替换 定时更新入口js文件的资源链接地址，防止有新的域名未进行配置 生成配置文件我这边使用的是coderecord编写的Python 脚本。 安装Python URLExtract库URLExtract库库可以提取文本中的链接地址。 12345678pip install idnapip install uritoolspip install urlextract# python3pip3 install idnapip3 install uritoolspip3 install urlextract 安装Python Requests库Requests库，http库。 1234pip install requests# python3pip3 install requests python 脚本新建py脚本 main.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# -*- coding: utf-8 -*-import hashlibimport requestsfrom urlextract import URLExtractsourceurl = \"https://maps.googleapis.com/maps/api/js\"maindomain = \"maps.your-domain.com\"mainapidomain = \"mapsapis.your-domain.com\"def getmd5(txt): hl = hashlib.md5() hl.update(txt.encode(encoding='utf-8')) return hl.hexdigest()def getAllLink(txt): extractor = URLExtract() urls = extractor.find_urls(txt) return urlsdef save(filename,content): with open(filename,\"w\") as w: for row in content: w.write(row+\"\\n\")def main(): source = requests.get(sourceurl) alllink = getAllLink(source.text) linkdata = [] for link in alllink: if \"https\" in link and link not in linkdata and \"www.google.cn\" not in link and \"maps.google.cn\" not in link: linkdata.append(link) replacefilter = [] location =[] alldomain = [] for row in linkdata: if(len(row)&gt;0): domain = row.replace(\"https://\",\"\").split(\"/\")[0] if domain in alldomain: continue alldomain.append(domain) if \"maps.googleapis.com\" in row: replacefilter.append(\"replace_filter %s %s ig;\"%(domain,mainapidomain)) elif \"www.google.com\" in row: replacefilter.append(\"replace_filter %s %s ig;\"%(domain,\"www.google.cn\")) else: md5val = getmd5(domain.replace(\".\",\"\")) replacefilter.append(\"replace_filter %s %s ig;\"%(domain,maindomain+\"/\"+md5val)) location.append(\"location /%s/ { proxy_pass %s; }\"%(md5val,\"https://\"+domain+\"/\")); #save nginx config save(\"replace.conf\",replacefilter) save(\"location.conf\",location)if __name__ == \"__main__\": main() 生成配置运行 main.py文件 1234python main.py# python3 python3 main.py 此时会生成replace.conf、location两个文件，这两个文件可以直接引入到NGINX中。 NGINX 配置NGINX我们需要使用到 replace-filter-nginx-module 模块。 检查环境运行 1234567nginx -V-----------nginx version: nginx/1.18.0built by gcc 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC)built with OpenSSL 1.1.1g 21 Apr 2020TLS SNI support enabledconfigure arguments: --prefix=/usr/local/nginx --user=www --group=www --with-http_stub_status_module --with-http_v2_module --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module --with-http_flv_module --with-http_mp4_module --with-openssl=../openssl-1.1.1g --with-pcre=../pcre-8.44 --with-pcre-jit --with-ld-opt=-ljemalloc --add-module=../replace-filter-nginx-module 注意查看configure argument中 是否存在replace-filter-nginx-module，如果存在可以直接跳到NGINX配置文件步骤， 如果不存在则需要重新编译安装NGINX。 安装 replace-filter-nginx-module如果你之前编译的文件还存在 直接之前的目录中编译是最好的，如果没有重新下载也是可以的， 但是注意，如果你的NGINX有其他的编译配置，记得也要在相应目录中下载这些依赖。 安装此模块需要先安装 sregex 运行库：1234git clone https://github.com/agentzh/sregexcd sregexmakemake install 下载replace-filter-nginx-module源码需要和NGINX源码文件夹 在同一层， 如果不在同一层，那么注意下面编译时的地址。 1git clone https://github.com/agentzh/replace-filter-nginx-module 重新编译 NGINX1234567891011121314151617181920212223242526272829303132333435&gt; nginx -Vnginx -V-----------nginx version: nginx/1.18.0built by gcc 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC)built with OpenSSL 1.1.1g 21 Apr 2020TLS SNI support enabledconfigure arguments: --prefix=/usr/local/nginx --user=www --group=www --with-http_stub_status_module --with-http_v2_module --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module --with-http_flv_module --with-http_mp4_module --with-openssl=../openssl-1.1.1g --with-pcre=../pcre-8.44 --with-pcre-jit --with-ld-opt=-ljemalloc # 得知NGINX版本是 1.18.0 下载NGINX源码&gt; wget http://nginx.org/download/nginx-1.18.0.tar.gz&gt; tar xzf nginx-1.18.0.tar.gz&gt; cd nginx-1.18.0# nginx -V 中的configure arguments参数最后面添加--add-module=./replace-filter-nginx-module&gt; ./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_stub_status_module --with-http_v2_module --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module --with-http_flv_module --with-http_mp4_module --with-openssl=../openssl-1.1.1g --with-pcre=../pcre-8.44 --with-pcre-jit --with-ld-opt=-ljemalloc --add-module=./replace-filter-nginx-module# 编译。&gt; make# 编译成功后测试是否正常，如果显示replace-filter-nginx-module则说明成功&gt; ./objs/nginx -Vnginx version: nginx/1.18.0built by gcc 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC)built with OpenSSL 1.1.1g 21 Apr 2020TLS SNI support enabledconfigure arguments: --prefix=/usr/local/nginx --user=www --group=www --with-http_stub_status_module --with-http_v2_module --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module --with-http_flv_module --with-http_mp4_module --with-openssl=../openssl-1.1.1g --with-pcre=../pcre-8.44 --with-pcre-jit --with-ld-opt=-ljemalloc --add-module=./replace-filter-nginx-module# 替换&gt; cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bak&gt; cp -rfp ./objs/nginx /usr/local/nginx/sbin/ 添加NGINX配置文件在NGINX配置目录下新建一个 googlemap的文件夹，将之前生成的replace.conf、location两个文件放入其中。 123456789101112131415161718192021222324252627282930313233343536373839server { listen 80; listen 443 ssl http2; ssl_certificate /usr/local/nginx/conf/ssl/maps.your-domain.com.crt; ssl_certificate_key /usr/local/nginx/conf/ssl/maps.your-domain.com.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers TLS13-AES-256-GCM-SHA384:TLS13-CHACHA20-POLY1305-SHA256:TLS13-AES-128-GCM-SHA256:TLS13-AES-128-CCM-8-SHA256:TLS13-AES-128-CCM-SHA256:EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; ssl_prefer_server_ciphers on; ssl_session_timeout 10m; ssl_session_cache builtin:1000 shared:SSL:10m; ssl_buffer_size 1400; add_header Strict-Transport-Security max-age=15768000; ssl_stapling on; ssl_stapling_verify on; server_name maps.your-domain.com mapsapis.your-domain.com; if ($ssl_protocol = &quot;&quot;) { return 301 https://$host$request_uri; } error_page 404 /404.html; #error_page 502 /502.html; location /maps/ { default_type text/javascript; proxy_set_header Accept-Encoding ''; proxy_pass https://maps.googleapis.com/maps/; replace_filter_max_buffered_size 500k; replace_filter_last_modified keep; replace_filter_types text/javascript application/javascript; include /usr/local/nginx/conf/googlemap/replace.conf; } location /maps-api-v3/ { proxy_pass https://maps.googleapis.com/maps-api-v3/; } include /usr/local/nginx/conf/googlemap/location.conf;} NGINX重载配置。这样就成功了。之后就调用https://maps.your-domain.com/maps/api/js使用 自动更新12345678910111213141516171819202122232425#!/bin/bashgooglemap_dir=\"/data/googlemap\"nginx_dir=\"/usr/local/nginx\"pushd ${googlemap_dir}python3 ${googlemap_dir}/main.pyif [ -f \"location.conf\" ]; then /bin/mv ${nginx_dir}/conf/googlemap/location.conf ${nginx_dir}/conf/googlemap/location.conf.bak /bin/mv ${nginx_dir}/conf/googlemap/replace.conf ${nginx_dir}/conf/googlemap/replace.conf.bak /bin/cp ${googlemap_dir}/location.conf ${nginx_dir}/conf/googlemap/location.conf /bin/cp ${googlemap_dir}replace.conf ${nginx_dir}/conf/googlemap/replace.conf ${nginx_dir}/sbin/nginx -t if [ $? == 0 ]; then echo \"Reload Nginx......\" ${nginx_dir}/sbin/nginx -s reload else /bin/mv ${nginx_dir}/conf/googlemap/location.conf.bak ${nginx_dir}/conf/googlemap/location.conf /bin/mv ${nginx_dir}/conf/googlemap/replace.conf.bak ${nginx_dir}/conf/googlemap/replace.conf echo \"Update googlemap ... FAILED]\" exit 1 fielse echo \"nginx conf failed\"fi 将脚本放入定时任务中即可。","link":"/post/Google-Map-Nginx-Reverse-Proxy/"},{"title":"BI报表工具：Metabase 部署","text":"因为运营的需求，会需要一些统计报表，但是因为目前人手不足，没有时间去开发一个bi报表统计系统， 并且他们的需求目前还是比较简单的统计， Metabase就很好的满足我们的需求了。 Metabase 介绍 这是他官网的简介。事实上试用了一段时间，他确实是一个简单易用的报表工具。 优点支持数据库类型繁多它支持以下数据库： Postgres MySQL Druid SQL Server Redshift MongoDB Google BigQuery SQLite H2 Oracle Vertica Presto Snowflake SparkSQL 非专业人士也能使用的查询你可以在数据模型中为每个字段配置别名， 这样在创建问题时，可以得到易读的字段筛选信息，并且提供了聚合/分组，即使是非开发人员也可以自由的创建sql查询语句。 各式各样的可视化图表格式各样的图表可视化， 总有一款适合你 =。= 方便的关联数据你可以直接在数据中关联各种其他的数据， 是要鼠标点击一下，你就可以跳转到关联数据中 SQL语句定义变量可以直接在sql中定义变量，添加筛选项，让报表更加实用 定时发送报表可以直接定义你要发送哪些报表，并且定时发送给指定的成员。 权限管理有成员分组，可以管理每个问题/图表的 修改/查看权限 支持谷歌登录/LDAP认证这个真的很方便，不用再去为每个人创建帐号了 缺点格式化功能很弱格式化仅限 时间/货币 等来进行格式化， 其他无法自定义格式化内容 字段类型支持问题 tinyint 问题：在mysql中 blob 其实就是tinyint(1)， 所以导致，如果你的数据库表中有存在tinyint(1) 的类型， 那么Metabase 会识别为布尔类型，并且无法更改， 你只能去改动数据库。 时间问题， 如果你的时间为 年月日/年月的时候， Metabase生成的表格 会自动改成为 年月日时分秒的格式， 你必须在查询的时候 去 定义返回字段格式为 ‘%Y-%m’才会正常显示 自定义查询弱自定义查询只能提供那么几个 固定的 方法， 无法去增加新的， 所以很多Sql，还是得靠自己去编写sql语句来查询。 变量类型少在sql语句中增加变量， 只有 时间/字符串/数值 等类型， 并且 时间 必须是 年月日 或者 年月日 时分秒 的格式， 如果有 查询月份的字段 就不可以了。 docker 安装部署时，最好映射数据库存储位置，方便后期更新升级使用。 这里我指定了版本号，是因为有时候最新版本是没有中文语言包的(需要等待翻译完成后才会被作者合并主分支中， 如果你想帮助翻译的话 可以 点击该链接 贡献你的翻译) 安装1docker run -d -p 3000:3000 -v /data/metabase:/metabase-data -e &quot;MB_DB_FILE=/metabase-data/metabase.db&quot; --name metabase metabase/metabase:v0.33.3 数据迁移mysql中Metabase 默认使用H4数据库， 官方推荐在生产环境中，最好更换为其他数据库比较稳定， 所以如果你在快速体验完毕后， 不想重新安装， 你可以直接将你目前的H4数据库 迁移到其他类型的数据库中(注意：只有你之前数据库映射出来才可以迁移。)。 首先停止你目前的Metabase容器。 在mysql数据库中创建一个数据库用于存储Metabase数据。 执行以下迁移命令 12345678910docker run --name metabase-migration \\ -v /data/metabase:/metabase-data \\ -e &quot;MB_DB_FILE=/metabase-data/metabase.db&quot; \\ -e &quot;MB_DB_TYPE=mysql&quot; \\ -e &quot;MB_DB_DBNAME=metabase&quot; \\ -e &quot;MB_DB_PORT=3306&quot; \\ -e &quot;MB_DB_USER=root&quot; \\ -e &quot;MB_DB_PASS=root&quot; \\ -e &quot;MB_DB_HOST=127.0.0.1&quot; \\ metabase/metabase:v0.33.3 load-from-h2 -v 填入你之前保存数据库的路径MB_DB_TYPE 代表你想使用的数据库类型load-from-h2 代表你想执行数据库迁移功能 执行该命令，可以看到迁移的过程。 创建新的容器迁移完成之后，你需要重新创建一个容器，执行Metabase数据库从mysql中获取PS: 可以删除上面2个容器咯。 12345678docker run -d -p 3000:3000 \\ -e &quot;MB_DB_TYPE=mysql&quot; \\ -e &quot;MB_DB_DBNAME=metabase&quot; \\ -e &quot;MB_DB_PORT=3306&quot; \\ -e &quot;MB_DB_USER=root&quot; \\ -e &quot;MB_DB_PASS=root&quot; \\ -e &quot;MB_DB_HOST=127.0.0.1&quot; \\ --name metabase metabase/metabase:v0.33.3 然后打开 127.0.0.1:3000 尽情享用吧。 使用添加数据库第一次打开页面， 跟着部署走，Metabase会要求你创建一个管理员帐号，和添加一个数据库。之后在添加数据库就需要 在 设置-管理员-数据库-添加数据库 来引入新的数据库了 编辑数据模型当你在添加完数据库后， 可能绝大部分表是不需要使用的，并且表字段意义可能不明确，非专业人员使用可能不知所意，所以你需要对你的数据库进行编辑，将不要使用的表隐藏起来，将表字段起一个别名。 这些都是在 设置-管理员-数据模型 中去设置的。 参考网站 Metabase 文档 Metabase GitHub地址 糖醋陈皮的博客-2019-1-18 Metabase 调研","link":"/post/Metabase-BI-deploy/"},{"title":"记录一次门罗币挖矿木马的追踪","text":"最近在整理服务器的时候，发现有一台服务器的状态不对， cpu占用一直是100%。 可是这个服务器没有跑什么程序，只有一个网站而已。于是登录服务器开始寻找原因。 查找问题一般出现服务器cpu异常，第一个想到的就是top命令了， 直接输入top ,却发现 没有程序有异常，cpu占用是0. 开始以为是阿里云的服务出错了，转念一想，阿里这种大厂不应该出这种低级错误吧。继续输入 vmstat 2 命令进行查看，确实cpu一直都是满载的。 如果是这样，那么说明应该是top被篡改了， 继续打开top 发现 cpu一直都是0，完全不动 =。= 更加肯定了我的想法。 单独查看进程却没发现 可疑的进程。于是开始谷歌， 发现有人docker有中过挖矿木马.输入docker ps -a 和docker image ls果然发现了两个奇怪的镜像和容器 12tanchao2014/mytestbusybox tanchao2014/mytest确实是一个挖矿的镜像，然而他并没有在运行， 看来这个服务器已经被入侵过几次了， 挖矿程序都更新换代了 =。= busybox 是一个Linux工具包，里面集成了许多工具和命令， 看来那个人就是用这个来对服务器做了点小动作。 先把挖矿镜像删除吧 1docker rmi tanchao2014/mytest 然后删除 busybox, 执行 1docker rm -fv (容器id) 提示 1Error response from daemon: driver &quot;overlay&quot; failed to remove root filesystem for 97213ce6fe42a93eb789a7d59e33eb815772899741d84ee2ee1aac20e5b0428f: remove /var/lib/docker/overlay/97213ce6fe42a93eb789a7d59e33eb815772899741d84ee2ee1aac20e5b0428f/merged: device or resource busy 看来是资源被占用了，那么我们需要查找是谁占用了资源，就把谁kill掉就好了。 1grep 97213ce6fe42a93eb789a7d59e33eb815772899741d84ee2ee1aac20e5b0428f /proc/*/mountinfo 找到占用资源的pid,然后直接 kill pid.再次输入 12docker rm -fv (容器id)docker rmi busybox 删除成功 删除容器的木马之后，发现一切又回到原点了。一代木马被删除了，二代还在继续奔跑。 直到在谷歌中发现了这篇文章： Linux 遭入侵，挖矿进程被隐藏案例分析 在 Linux 操作系统的动态链接库加载过程中，动态链接器会读取 LD_PRELOAD 环境变量的值和默认配置文件 /etc/ld.so.preload 的文件内容，并将读取到的动态链接库进行预加载，即使程序不依赖这些动态链接库，LD_PRELOAD 环境变量和 /etc/ld.so.preload 配置文件中指定的动态链接库依然会被装载，它们的优先级比 LD_LIBRARY_PATH 环境变量所定义的链接库查找路径的文件优先级要高，所以能够提前于用户调用的动态库载入。 ——段落引自《警惕利用 Linux 预加载型恶意动态链接库的后门》 立刻动手去看。 解决问题首先进入到/etc/ld.so.preload 中查看，果然，有一个动态链库安静的躺在里面。 /usr/lib/libc.so.8 先把它给干掉： 1rm /usr/lib/libc.so.8 然后删除 ld.so.preload文件删除的时候提示了权限不足， 是因为 该文件被增加了 i a属性。输入 1lsattr ld.so.preload 可以看到 文件属性中包含 i a属性。 12345678910111213a 即append，设定该参数后，只能向文件中添加数据，而不能删除，多用于服务器日志文件安全，只有root才能设定这个属性i 文件不能被删除、改名、设定链接关系，同时不能写入或新增内容（即使是root用户）。只有root才能设定这个属性c 即compresse，文件会自动的经压缩后再存储，读取时会自动的解压d 即no dump，设定文件不能成为dump程序的备份目标j 即journal，设定此参数使得当通过mount参数”data=ordered”或”data=writeback”挂载的文件系统，文件在写入时会先被记录(在journal中)。如果filesystem被设定参数为data=journal，则该参数自动失效s 即secure，保密选项。设置了s属性的文件在被删除时，其所有数据块会被写入0u 即undelete，反删除选项。与s相反，文件在被删除时，其所有的数据块都保留着，用户今后可以恢复该文件 使用 chattr命令移除即可。 123chattr -ia ld.so.preload rm ld.so.preload linux文件系统高级权限属性 那么实际的木马进程到底怎么查看了， 我想到了入侵人使用的 busybox. 下载安装下来 使用一下看看。 1234wget https://busybox.net/downloads/binaries/1.30.0-i686/busyboxmv busybox /usr/bin/chmod 755 /usr/bin/busyboxbusybox top 很明显的看到了 systemd-host这个进程。 12kill 7907cd /usr/lib/systemd/ 成功找到。 并且还找到他使用的链库文件夹，在 /usr/lib/systemd/lib文件夹里面下载删除， 慢慢研究。 日志分析矿池地址： 12139.99.123.196:443139.99.124.170:443 钱包地址： 143U3d1PBg4Gi2BaeMx7nH2dQsyZhAdMRATkJmbvr3kFuEMvU93f4H5geqjnru7SjLA3q81xCnUWr9PdFJRKDB5131fbC8pE 进入门罗币 查询该钱包， 发现目前有200多个机器正在崩跑 参考 BusyBox linux常见backdoor及排查技术 SO文件反汇编实践","link":"/post/Monero-Trojan-Track/"},{"title":"Python监测树莓派温度状态","text":"4月底气温已经慢慢升高了，之前树莓派没有增加散热片以及风扇，导致温度太高，把TF卡给烧坏了(心疼3S)。为了不要让这种事情发生，立马把风扇给配上了。虽然把风扇加上了，为了再多加一个保险，自己用Python写了一个监控脚本，当温度达到某个值时，将会发送到微信报警。 获取系统状态首先，我们需要知道树莓派各项参数。 CPU相关树莓派获取CPU温度的命令是： vcgencmd measure_temp 获取CPU使用情况可以通过top来抓取到。因为我只需要获取到cpu的使用情况，所以通过aws可以匹配抓取到我们想要的数据 top -n1 | awk ‘/Cpu(s):/ {print $2}’ 内存使用情况通过 free命令可以得到我们当前内存的使用情况 获取磁盘状态 df -h / 通知服务这里使用的微信提醒服务是 Server酱，Server酱是从服务器推报警和日志到手机的工具，特方便的一点就是，只有一个接口，并且直接使用github登陆即可注册。 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495# coding=utf-8import osimport requestsimport jsonimport time# 获取CPU温度def getCPUtemperature(): res = os.popen('vcgencmd measure_temp').readline() return(res.replace(\"temp=\",\"\").replace(\"'C\\n\",\"\"))# 获取内存状态def getRAMinfo(): p = os.popen('free') i = 0 while 1: i = i + 1 line = p.readline() if i==2: return(line.split()[1:4])# 获取CPU使用情况def getCPUuse(): return(str(os.popen(\"top -n1 | awk '/Cpu\\(s\\):/ {print $2}'\").readline().strip()))# 获取磁盘状态def getDiskSpace(): p = os.popen(\"df -h /\") i = 0 while 1: i = i +1 line = p.readline() if i==2: return(line.split()[1:5])# POST 到自己的服务器上 之后做他用def getPostServer(CPUData): url = \"http://xxx.xxx/xxx\" CPUData['time'] = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) requests.post (url, data = CPUData) # 将数据POST到服务器上# 发送数据到微信def getPostWinxin(CPUData): url = \"https://sc.ftqq.com/you token.send\" param = {'text':'树莓派温度达到' + CPUData['CPU_temp'] + '°C了', 'desp':'## 树莓派信息 \\n &gt; CPU 温度 = ' +CPUData['CPU_temp'] + '°C \\nCPU 用量 = '+ CPUData['CPU_usage'] + '% \\n总内存 = '+str(CPUData['RAM_total'])+' MB \\n使用内存 = '+str(CPUData['RAM_used'])+' MB \\n剩余内存 = '+str(CPUData['RAM_free'])+' MB \\n磁盘空间 = '+str(CPUData['DISK_total'])+'B \\n已使用 = '+str(CPUData['DISK_used'])+'B \\n百分比 = '+str(CPUData['DISK_perc'])} requests.post (url, data = param)# 检查字符串是否是JSON格式 是则返回对象def check_json(strData): try: return json.loads(strData) except: return FalseRAM_stats = getRAMinfo()DISK_stats = getDiskSpace()data = { 'CPU_temp' : getCPUtemperature(), 'CPU_usage': getCPUuse(), 'RAM_stats': getRAMinfo(), 'RAM_total': round(int(RAM_stats[0]) / 1000,1), 'RAM_used' : round(int(RAM_stats[1]) / 1000,1), 'RAM_free' : round(int(RAM_stats[2]) / 1000,1), 'DISK_total' : DISK_stats[0], 'DISK_used' : DISK_stats[1], 'DISK_perc' : DISK_stats[3]}getPostServer(data)if float(data['CPU_temp']) &gt; 60.0: filePath = \"/home/pi/pi.json\" if not os.path.exists(filePath): fileData = open(filePath, 'w+') else: fileData = open(filePath, 'rw+') fileStrArr = check_json(fileData.read()) # 如果文本不存在数据或者不是标准的JSON 格式 if not fileStrArr: fileArr = {\"time\":int(time.time()), 'number': 1} getPostWinxin(data) else: nowtime = int(time.time()) if fileStrArr['time'] + 1800 &lt; nowtime: fileArr = {\"time\":int(time.time()), 'number': fileStrArr['number'] + 1} getPostWinxin(data) else: fileArr = fileStrArr fileData.write(json.dumps(fileArr)) fileData.close()","link":"/post/Python-monitoring-raspberry-pi-status/"},{"title":"QNAP 共享多功能打印机的扫描仪","text":"家里有一台佳能mp288的打印机，按照正常的操作，连接TS-453Bmini已经能正常共享打印了，但是扫描仪功能却没有办法使用，每次需要用到扫描仪的时候还要把打印机USB重新插入PC上才行，用起来十分不得劲。于是乎开始寻求万能的谷歌，发现群晖有个软件可以实现扫描仪的共享，而QNAP却没有…… 好吧，谁叫我买的是QNAP呢，只能继续折腾了。这样查查找找弄了半天，终于找到2个解决方案。 方案USB网关 - virtualherevirtualhere 是一个UBS网关的软件，它有服务端和客户端两个软件，可以通过客户端软件直接挂载服务端上面的USB设备。相当于直接把远程计算机上面的设备直接连接到你的电脑，这样就无关NAS上面是否支持扫描仪或者没有驱动无法使用的问题了。 优点 基本全平台，支持NAS/MAC OS/Windows/Android等平台，基本涵盖了主流的平台设备； 无需担心驱动问题，因为是直接挂载在你的电脑上面，把它当做一个本地设备就可以了； 配置简单，以上平台都有安装包，直接安装使用即可 缺点 要花钱… 客户端免费，服务端终生49美元。 只能挂载一个客户端，如果有人挂载了设备，必须等其他人在客户端卸载设备后才能在其他设备挂载。 他有QNAP的安装包，可以直接安装使用，安装后可以免费使用10天。测试之后能够达到我的目的，但是因为一旦挂载之后，，其他人就必须等我卸载才能使用感觉不是很方便，所以又开始查询其他的解决方案。 Linux扫描仪软件 - sane-project找了很久，最后在QNAP英文论坛里面找了一篇 USB scanner server: got it working on Qnap 的帖子，发现这就是我想要的方案。大佬使用的是一个叫sane-project 的 Linux扫描仪软件来实现的。 官网是这样介绍的： sane-project 是一个应用程序编程接口（API），它提供给任何光栅图像扫描仪硬件标准化的访问（平板扫描仪，手持式扫描仪，视频和静止相机，图像采集卡等。 ） 安装sane-project由于帖子年代久远有些地方无法适用了，所以基于上面帖子更新一下现在的安装方法： 查询支持列表请在下面列表中查找你的设备型号， 看能否支持。 安装Entware软件包库在 Entware WiKi中下载对应的QPKG文件，在你的NAS上面进行安装。 PS： 安装后 Entware 的目录在： /opt/etc 安装 xinetd、sane-backends软件通过SSH进入你的NAS，命令行输入： opkg install xinetdopkg install sane-backends 检测扫描仪上面程序安装完毕之后，打开你的打印机或者扫描仪，连接NAS，在命令行中输入： scanimage -L 如果可以支持你的设备的话，应该有类似以下的输出： device `pixma:04A91746_226D25’ is a CANON Canon PIXMA MP280 multi-function peripheral 配置sane-backends进程守护 -xinetd为了能正常使用和开机启动，需要配置xinetd增加一个xinetd的配置文件 cd /opt/etc/xinetd.dvi saned 保存如下配置： 1234567891011service saned{port = 6566 # 服务的端口socket_type = streamserver = /opt/sbin/saned # sane-backends的位置protocol = tcpuser = admin #执行程序使用的用户group = administratorswait = nodisable = no} 在系统配置sane-backends的端口协议首先备份是个好习惯： cp /etc/services /etc/services.back 然后打开文件: vi /etc/services 在文件最后一行保存以下文字： 1saned 6566/tcp # SANE network scanner daemon 配置sane-backends打开配置文件 vi /opt/etc/sane.d/saned.conf 增加以下文字 1192.168.1.1/24 PS:我的内网网段是192.168.1.1直到192.168.1.255 使用子网掩码：255.255.255.0，所以是/24，如果你的掩码如255.255.0.0应该使用：192.168.1.1/16 修改xinetd 配置打开配置文件 vi /opt/etc/xinetd.conf 配置如下： 123456789defaults{ only_from = localhost 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16 instances = 60 log_type = SYSLOG authpriv info log_on_success = HOST PID log_on_failure = HOST cps = 25 30} 启动 xinetd -d // debug 第一次使用先用这个启动查看是否有问题xinetd // 启动命令 使用Windows 下载：sanetwain 启动后输入你NAS的IP地址就可以连接正常使用了。其他设备可以去看看 sane-project 官网 里面有自带的sane-frontends 也有推荐的其他软件。 PS： sanetwain 扫描的时候记得去调整一下 扫描的DPI 哦，否则扫描出来会比较模糊的。 总结我最后选择了sane-project 是因为他可以直接使用扫描仪功能，而且还不会影响NAS的打印机功能。两者可以完美兼容，使用非常方便，而virtualhere无法做到这一点。不过还是希望QNAP能够加强生态的建设， 能让他人少折腾一点就可以直接开箱即用~","link":"/post/QNAP-TS-453Bmini-Shared-Printer-scan/"},{"title":"NAS-QNAP TS-453Bmini折腾一：选择篇","text":"NAS这个词第一次是在大学逛论坛的时候看到的，看到论坛里面的人各种折腾，心里不以为然，觉得这些东西不实用啊。在学校，一个树莓派在校园网里面就可以玩出各种花样，干嘛要花那么多钱？ 后面开始工作了，家里设备也多起来了，手机、PAD、电视、电脑、笔记本、智能家具等等，虽然树莓派可以做到共享文件，但是一个是配置麻烦还不稳定，另一个就是手机没有对应APP使用也挺麻烦的，这时候开始理解大佬们为什么要买NAS了。 刚开始为了体验一下NAS，自己在家里的小主机上安装了一个黑群晖，使用了3个月后，决定我要剁手了….. 需求首先明确需求，我购买NAS主要需求有这些： 设备终端之间影音、照片等文件共享 能随时随地在外网访问NAS中的文件 下载工具(能远程下载，回家就可以直接看下载好的视频) Time Machine备份 家庭影音管理(能整理下载的各种电影电视剧文件) Homekit的对接(之前是用树莓派，迁移到NAS方便统一管理) 对比现在家庭NAS有以下几种选择： 自己组装设备，安装免费NAS系统或者黑群晖 群晖 威联通 第一种自己组装设备，之前已经有安装过黑群晖了，但是很多服务并不能使用，很不方便；免费的NAS系统的话需要好好折腾一番，而且还是没有商业的NAS好用，所以PASS 第二种群晖，其实最开始接触NAS，第一个知道的就是群晖。根据上面黑群晖的使用来说，确实很方便，无奈太贵，配置太低。 第三种威联通，这是我最终选择的，之前在群晖和威联通纠结了很久很久：群晖网上各种教程，软件也比威联通多，但是太贵；威联通在群晖同等价位上面，配置要高于群晖一个阶段。最终双十一的时候威联通的价格打动了我，立马就下单了 =。= (果然，对于穷人来说，价格的诱惑是致命的) 设备这次购买的是威联通(QNAP) TS-452Bmini。 硬盘位4个，家庭基本足够使用了； CPU是J3455，核显HD G500，可以支持硬解以及虚拟化技术； 内存4G，2个内存槽(这个很坑，原装2根2G的，加内存的话原装的就得必须丢弃一根)； 2个千兆网口 4个USB口(3个3.0，1个2.0) 一个HDMI接口，用于他自己的一个虚拟桌面系统(没啥用，还很卡) 内存这边我购买了一根8G的内存，替换掉自带的一根2G内存，组成10G内存。 硬盘的购买纠结的很久，由于威联通这款是他们的低端产品，没有单独的M2接口，而为了使用更加流畅系统盘当然要使用SSD才行，所以系统盘需要占用一个硬盘位。选来选去选择了英睿达的BX500系列，原因嘛，还是便宜，而且自己产芯片也比杂牌有保障的。(事实证明也确实很坚挺，由于ups故障，NAS断电了4-5次，目前一切良好) 还有3个盘位，准备选择西数的硬盘，这时候纠结在是买NAS红盘还是普通蓝盘了，NAS红盘稳定，价格也是昂贵的，蓝盘稳定性不如红盘，但是一块红盘的价格可以买两块蓝盘了。 经过再三的考虑，选择了蓝盘，原因如下： 价格便宜。 本人不挂PT下载，硬盘读写没有那么多。 重要的资料会使用云盘同步，保证多备份，NAS存在是为了更加方便快捷的能读取到数据。 以上就是目前家中配置的nas 的过程了。","link":"/post/QNAP-TS-453Bmini-configuration-1/"},{"title":"PHP7.1使用openssl 替换 废弃加密方法-mcrypt","text":"最近在接入一个三方支付， 他们给的demo程序中，使用的加解密函数是通过 mcrypt 方法进行的。而 mcrypt 在7.1 版本的时候已经被弃用， 目前使用的版本为7.2， 所以需要找到替代函数将他们替换掉。 加密函数123456789101112function encrypt($input, $key) { $size = mcrypt_get_block_size(MCRYPT_RIJNDAEL_128, MCRYPT_MODE_ECB); $input = pkcs5_pad($input, $size); $td = mcrypt_module_open(MCRYPT_RIJNDAEL_128, '', MCRYPT_MODE_ECB, ''); $iv = mcrypt_create_iv (mcrypt_enc_get_iv_size($td), MCRYPT_RAND); mcrypt_generic_init($td, $key, $iv); $data = mcrypt_generic($td, $input); mcrypt_generic_deinit($td); mcrypt_module_close($td); $data = base64_encode($data); return $data; } 使用openssl函数重写： 1234function opensslEncrypt($input, $key) { $data = openssl_encrypt($input,'AES-128-ECB',$key); return $data; } 解密函数123456789101112function encrypt($input, $key) { $size = mcrypt_get_block_size(MCRYPT_RIJNDAEL_128, MCRYPT_MODE_ECB); $input = pkcs5_pad($input, $size); $td = mcrypt_module_open(MCRYPT_RIJNDAEL_128, '', MCRYPT_MODE_ECB, ''); $iv = mcrypt_create_iv (mcrypt_enc_get_iv_size($td), MCRYPT_RAND); mcrypt_generic_init($td, $key, $iv); $data = mcrypt_generic($td, $input); mcrypt_generic_deinit($td); mcrypt_module_close($td); $data = base64_encode($data); return $data; } 使用openssl函数重写： 1234function opensslDecrypy($input, $key) { $decrypted = openssl_decrypt( $sStr, 'AES-128-ECB',$sKey); return $decrypted; } 验证测试类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192$str = json_encode(['a' =&gt; 1, 'b' =&gt; 2]);$Encr = new AesCryptUtil();$key = 'eeqIYJna6NHfwiqi';$en1 = $Encr::mcryptEncrypt($str,$key);$en2 = $Encr::opensslEncrypt($str,$key);$den1= $Encr::mcryptDecrypt($en1,$key);$den2= $Encr::opensslDecrypt($en2,$key);echo \"加密前数据：\".$str.\"\\r\\n\";echo \"Encrypt加密后数据：\".$en1.\"\\r\\n\";echo \"Decrypt解密的数据：\".$den1.\"\\r\\n\";echo \"openssl加密后数据：\".$en2.\"\\r\\n\";echo \"openssl解密的数据：\".$den2.\"\\r\\n\"; class AesCryptUtil{ /** * [encrypt description] * 使用mcrypt库进行加密 * @param [type] $input * @param [type] $key * @return [type] */ public static function mcryptEncrypt($input, $key) { $size = mcrypt_get_block_size(MCRYPT_RIJNDAEL_128, MCRYPT_MODE_ECB); $input = self::pkcs5Pad($input, $size); $td = mcrypt_module_open(MCRYPT_RIJNDAEL_128, '', MCRYPT_MODE_ECB, ''); $iv = mcrypt_create_iv (mcrypt_enc_get_iv_size($td), MCRYPT_RAND);//MCRYPT_DEV_URANDOM mcrypt_generic_init($td, $key, $iv); $data = mcrypt_generic($td, $input); mcrypt_generic_deinit($td); mcrypt_module_close($td); $data = base64_encode($data); return $data; } /** * [pkcs5Pad description] * @param [type] $text * @param [type] $blocksize * @return [type] */ private static function pkcs5Pad($text, $blocksize) { $pad = $blocksize - (strlen($text) % $blocksize); return $text . str_repeat(chr($pad), $pad); } /** * [decrypt description] * 使用mcrypt库进行解密 * @param [type] $sStr * @param [type] $sKey * @return [type] */ public static function mcryptDecrypt($sStr, $sKey) { $iv = mcrypt_create_iv(mcrypt_get_iv_size(MCRYPT_RIJNDAEL_128, MCRYPT_MODE_ECB), MCRYPT_RAND);//MCRYPT_DEV_URANDOM $decrypted = mcrypt_decrypt(MCRYPT_RIJNDAEL_128, $sKey, base64_decode($sStr), MCRYPT_MODE_ECB, $iv); $dec_s = strlen($decrypted); $padding = ord($decrypted[$dec_s-1]); $decrypted = substr($decrypted, 0, -$padding); return $decrypted; } /** * [opensslDecrypt description] * 使用openssl库进行加密 * @param [type] $sStr * @param [type] $sKey * @return [type] */ public static function opensslEncrypt($sStr, $sKey, $method = 'AES-128-ECB'){ $str = openssl_encrypt($sStr,$method,$sKey); return $str; } /** * [opensslDecrypt description] * 使用openssl库进行解密 * @param [type] $sStr * @param [type] $sKey * @return [type] */ public static function opensslDecrypt($sStr, $sKey, $method = 'AES-128-ECB'){ $str = openssl_decrypt($sStr,$method,$sKey); return $str; } }/*加密前数据：{\"a\":1,\"b\":2}Encrypt加密后数据：eVWVjTcQ0pp78DL4MrvReg==Decrypt解密的数据：{\"a\":1,\"b\":2}openssl加密后数据：eVWVjTcQ0pp78DL4MrvReg==openssl解密的数据：{\"a\":1,\"b\":2}*/","link":"/post/php-71-openssl-mcrypt/"},{"title":"php curl 浏览器访问 https 为空，curl 错误代码 77","text":"在curl请求一个HTTPS网站时，返回内容为空，命令行执行访问正常，curl_error没有返回错误信息，curl_errno返回错误码为77。这种情况是因为服务器本地的ca证书有问题。需要安装一遍即可。 安装证书 1yum install ca-certificates 2.重启php-fpm 1&gt; service php-fpm restart ps: 如果存在以下报错，说明php-fpm为注册成系统服务。 12Redirecting to /bin/systemctl restart php-fpm.serviceFailed to restart php-fpm.service: Unit not found. 解决：查询php-fpm 的pid： 1234567&gt; ps -aux |grep phproot 786 0.0 0.6 238024 6584 ? Ss 2019 3:40 php-fpm: master process (/usr/local/etc/php/php-fpm.conf)nginx 11569 0.0 1.3 322920 13372 ? S 1月29 0:43 php-fpm: pool wwwnginx 11614 0.0 1.3 322972 13452 ? S 1月29 0:29 php-fpm: pool wwwnginx 18184 0.0 1.2 322852 13120 ? S 1月31 0:16 php-fpm: pool wwwroot 23325 0.0 0.0 112728 972 pts/0 R+ 00:57 0:00 grep --color=auto php 执行： 12&gt; kill -USR2 786 # 重启&gt; kill INT/TERM 786 # 关闭 3.完成 成功解决问题","link":"/post/php-curl-https-error-code-77/"},{"title":"mysql 从库部署","text":"因为最近业务需求，需要建立一个数据仓库，为了避免主库受到影响，所以需要建立一个从库给数据仓库提供源数据。 目前2台机器都是 阿里云ECS云服务器， 所以两者通讯可以直接使用内网连接。 主库配置修改主库配置文件 my.cnf : 1234567891011[mysqld]# 数据库唯一id， 该id 必须和其他链接的数据库不同server-id= 1#启用二进制日志；log-bin=mysql-bin# 日志格式， 有Mixed,Statement,Row三种，默认格式是 Statement，Mixed相当于前两种模式的结合binlog_format=mixed# 二进制日志自动删除/过期的天数。默认值为0，表示不自动删除。expire_logs_days = 10# 可以选择需要同步哪些库binlog-do-db=need_db 修改后， 保存，并重启数据库。 重启完成后，进入mysql，创建一个从库同步使用的帐号： 1234&gt; mysql -uroot -pmysql&gt; CREATE USER 'slave'@'172.18.18.2' IDENTIFIED BY '123456';mysql&gt; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%'; 创建帐号时， 为了安全着想 最好指定host参数，我这里填写的是从库阿里云的内网地址。 锁表，避免这段时间有新的数据产生， 执行 show master status 记住Position 12345678mysql&gt; FLUSH TABLES WITH READ LOCK;mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 154 | need_db | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 从库配置修改从库配置文件 my.cnf : 1234567891011121314[mysqld]# 数据库唯一id， 该id 必须和其他链接的数据库不同server-id= 1#启用二进制日志；log-bin=mysql-bin# 日志格式， 有Mixed,Statement,Row三种，默认格式是 Statement，Mixed相当于前两种模式的结合binlog_format=mixed# 二进制日志自动删除/过期的天数。默认值为0，表示不自动删除。expire_logs_days = 10# 可以选择需要同步哪些库replicate-do-db=need_db#如果发现主服务器断线，重新连接的时间差； master-connect-retry=60 保存并重启mysql服务。 重启完成后，进入mysql，开始配置主从链接 12345678910&gt; mysql -uroot -p# 先停止slave服务mysql&gt; slave stop;# 配置主从参数mysql&gt; change master to master_host='172.18.18.2', master_user='slave', master_password='123456', master_port=3306, master_log_file='mysql-bin.000001', master_log_pos=154, master_connect_retry=30; # 启动slave服务mysql&gt; slave start; 参数解释：1234567master_host: Master 的IP地址master_user: 在 Master 中授权的用于数据同步的用户master_password: 同步数据的用户的密码master_port: Master 的数据库的端口号master_log_file: 指定 Slave 从哪个日志文件开始复制数据，即上文中提到的 File 字段的值master_log_pos: 从哪个 Position 开始读，即上文中提到的 Position 字段的值master_connect_retry: 当重新建立主从连接时，如果连接失败，重试的时间间隔，单位是秒，默认是60秒。 然后回到主库，解锁表 1mysql&gt; unlock tables; 回到从库查看状态： 1mysql&gt; show slave status \\G; 如果 SlaveIORunning 和 SlaveSQLRunning 是Yes 说明已经正常工作了","link":"/post/mysql-master-slave/"},{"title":"docker TLS认证 配置","text":"生成证书可以直接使用openssl生成证书，也可以使用工具来生成证书。 我是使用certstrap 工具直接生成证书，所以后面配置也以 certstrap为准 openssl 生成证书123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#!/bin/bash# # -------------------------------------------------------------# 自动创建 Docker TLS 证书# -------------------------------------------------------------# 以下是配置信息# --[BEGIN]------------------------------CODE=\"dp\"IP=\"docker服务器ip\"PASSWORD=\"证书密码\"COUNTRY=\"CN\"STATE=\"BEIJING\"CITY=\"BEIJING\"ORGANIZATION=\"公司\"ORGANIZATIONAL_UNIT=\"Dev\"COMMON_NAME=\"$IP\"EMAIL=\"邮箱\"# --[END]--# Generate CA keyopenssl genrsa -aes256 -passout \"pass:$PASSWORD\" -out \"ca-key-$CODE.pem\" 4096# Generate CAopenssl req -new -x509 -days 365 -key \"ca-key-$CODE.pem\" -sha256 -out \"ca-$CODE.pem\" -passin \"pass:$PASSWORD\" -subj \"/C=$COUNTRY/ST=$STATE/L=$CITY/O=$ORGANIZATION/OU=$ORGANIZATIONAL_UNIT/CN=$COMMON_NAME/emailAddress=$EMAIL\"# Generate Server keyopenssl genrsa -out \"server-key-$CODE.pem\" 4096# Generate Server Certs.openssl req -subj \"/CN=$COMMON_NAME\" -sha256 -new -key \"server-key-$CODE.pem\" -out server.csrecho \"subjectAltName = IP:$IP,IP:127.0.0.1\" &gt;&gt; extfile.cnfecho \"extendedKeyUsage = serverAuth\" &gt;&gt; extfile.cnfopenssl x509 -req -days 365 -sha256 -in server.csr -passin \"pass:$PASSWORD\" -CA \"ca-$CODE.pem\" -CAkey \"ca-key-$CODE.pem\" -CAcreateserial -out \"server-cert-$CODE.pem\" -extfile extfile.cnf# Generate Client Certs.rm -f extfile.cnfopenssl genrsa -out \"key-$CODE.pem\" 4096openssl req -subj '/CN=client' -new -key \"key-$CODE.pem\" -out client.csrecho extendedKeyUsage = clientAuth &gt;&gt; extfile.cnfopenssl x509 -req -days 365 -sha256 -in client.csr -passin \"pass:$PASSWORD\" -CA \"ca-$CODE.pem\" -CAkey \"ca-key-$CODE.pem\" -CAcreateserial -out \"cert-$CODE.pem\" -extfile extfile.cnfrm -vf client.csr server.csrchmod -v 0400 \"ca-key-$CODE.pem\" \"key-$CODE.pem\" \"server-key-$CODE.pem\"chmod -v 0444 \"ca-$CODE.pem\" \"server-cert-$CODE.pem\" \"cert-$CODE.pem\"# 打包客户端证书mkdir -p \"tls-client-certs-$CODE\"cp -f \"ca-$CODE.pem\" \"cert-$CODE.pem\" \"key-$CODE.pem\" \"tls-client-certs-$CODE/\"cd \"tls-client-certs-$CODE\"tar zcf \"tls-client-certs-$CODE.tar.gz\" *mv \"tls-client-certs-$CODE.tar.gz\" ../cd ..rm -rf \"tls-client-certs-$CODE\"# 拷贝服务端证书mkdir -p /etc/docker/certs.dcp \"ca-$CODE.pem\" \"server-cert-$CODE.pem\" \"server-key-$CODE.pem\" /etc/docker/certs.d/ certstrap 生成证书安装/编译 123$ git clone https://github.com/square/certstrap$ cd certstrap$ ./build 生成CA证书： 12345$ bin/certstrap init --common-name \"Root CA\"Created out/Root_CA.keyCreated out/Root_CA.crtCreated out/Root_CA.crl 生成服务器证书： 12345678910$ # 172.16.10.128为服务器IP$ bin/certstrap request-cert -common-name server -ip 172.16.10.128Created out/server.keyCreated out/server.csr$ bin/certstrap sign server --CA Root_CA --years 10Created out/server.crt from out/server.csr signed by out/Root_CA.key 生成客户端证书： 123456789$ bin/certstrap request-cert -common-name localhost -ip 127.0.0.1Created out/localhost.keyCreated out/localhost.csr$ bin/certstrap sign localhost --years 10 --CA Root_CACreated out/localhost.crt from out/localhost.csr signed by out/Root_CA.key 查看证书： 1234567891011$ ll391190 -r--r--r-- 1 root root 1521 9月 7 22:09 localhost.crt * 客户端证书391188 -r--r--r-- 1 root root 936 9月 7 22:09 localhost.csr 391189 -r--r----- 1 root root 1679 9月 7 22:09 localhost.key * 客户端私钥391182 -r--r--r-- 1 root root 1525 9月 7 22:04 server.crt * 服务端证书391148 -r--r--r-- 1 root root 944 9月 7 21:57 server.csr391181 -r--r----- 1 root root 1679 9月 7 21:57 server.key * 服务端私钥391147 -r--r--r-- 1 root root 922 9月 7 21:55 Root_CA.crl391143 -r--r--r-- 1 root root 1757 9月 7 21:55 Root_CA.crt * CA证书391144 -r--r----- 1 root root 3243 9月 7 21:55 Root_CA.key 配置docker停止docker, 修改docker 服务 配置文件 12$ systemctl stop docker$ vim /lib/systemd/system/docker.service 将原来配置文件中的启动命令注释掉 1ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 改为 1ExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/root/.docker/Root_CA.crt --tlscert=/root/.docker/server.crt --tlskey=/root/.docker/server.key -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock 重载服务，启动docker 12$ systemctl daemon-reload$ systemctl start docker","link":"/post/docker-tls-certification-configuration/"},{"title":"安装opencc4php 扩展 centos","text":"opencc4php 是OpenCC的PHP扩展,可以很方便的对语句进行简繁体转换。 安装依赖12$ yum install doxygen //doxygen$ yum install cmake //cmake 安装OpenCC1234567891011$ cd /data/opencc$ git clone https://github.com/BYVoid/OpenCC.git$ cd OpenCC/$ make$ make install$ # 验证是否安装成功$ opencc --versionOpen Chinese Convert (OpenCC) Command Line ToolVersion: 1.0.5 PS: 如果提示：opencc: error while loading shared libraries: libopencc.so.2: cannot open shared object file: No such file or directory 错误， 是因为 64位系统没有对应的链库导致的。执行以下命令： 123$ find / -name libopencc.so.2/usr/lib/libopencc.so.2$ ln -s /usr/lib/libopencc.so.2 /usr/lib64/libopencc.so.2 安装opencc4php12345678$ cd /usr/local$ git clone https://github.com/NauxLiu/opencc4php.git$ cd opencc4php$ phpize //具体的文件地址自行查找$ ./configure --with-opencc=/data/OpenCC --with-php-config=/usr/local/php/bin/php-config //自行修改 opencc目录和 php-config目录$ make test //测试有什么问题没有$ make $ make install PHP配置文件 追加配置1234[openCC]#extension_dir 地址应该看上面 opencc4php 安装完毕后的位置在哪里extension_dir =/usr/local/php/lib/php/extensions/no-debug-non-zts-20170718/extension=opencc.so","link":"/post/install-opencc4php/"}],"tags":[{"name":"switch","slug":"switch","link":"/tags/switch/"},{"name":"动物森友会","slug":"动物森友会","link":"/tags/%E5%8A%A8%E7%89%A9%E6%A3%AE%E5%8F%8B%E4%BC%9A/"},{"name":"game","slug":"game","link":"/tags/game/"},{"name":"GoogleMap","slug":"GoogleMap","link":"/tags/GoogleMap/"},{"name":"反代","slug":"反代","link":"/tags/%E5%8F%8D%E4%BB%A3/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Metabase","slug":"Metabase","link":"/tags/Metabase/"},{"name":"报表","slug":"报表","link":"/tags/%E6%8A%A5%E8%A1%A8/"},{"name":"BI","slug":"BI","link":"/tags/BI/"},{"name":"统计","slug":"统计","link":"/tags/%E7%BB%9F%E8%AE%A1/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"Monero","slug":"Monero","link":"/tags/Monero/"},{"name":"木马","slug":"木马","link":"/tags/%E6%9C%A8%E9%A9%AC/"},{"name":"挖矿","slug":"挖矿","link":"/tags/%E6%8C%96%E7%9F%BF/"},{"name":"树莓派","slug":"树莓派","link":"/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/"},{"name":"Raspberry Pi","slug":"Raspberry-Pi","link":"/tags/Raspberry-Pi/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"nas","slug":"nas","link":"/tags/nas/"},{"name":"QNAP","slug":"QNAP","link":"/tags/QNAP/"},{"name":"打印机","slug":"打印机","link":"/tags/%E6%89%93%E5%8D%B0%E6%9C%BA/"},{"name":"硬件","slug":"硬件","link":"/tags/%E7%A1%AC%E4%BB%B6/"},{"name":"php","slug":"php","link":"/tags/php/"},{"name":"openssl","slug":"openssl","link":"/tags/openssl/"},{"name":"mcrypt","slug":"mcrypt","link":"/tags/mcrypt/"},{"name":"curl","slug":"curl","link":"/tags/curl/"},{"name":"证书","slug":"证书","link":"/tags/%E8%AF%81%E4%B9%A6/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"从库","slug":"从库","link":"/tags/%E4%BB%8E%E5%BA%93/"},{"name":"certstrap","slug":"certstrap","link":"/tags/certstrap/"},{"name":"tls","slug":"tls","link":"/tags/tls/"},{"name":"opencc","slug":"opencc","link":"/tags/opencc/"},{"name":"opencc4php","slug":"opencc4php","link":"/tags/opencc4php/"}],"categories":[{"name":"玩玩游戏","slug":"玩玩游戏","link":"/categories/%E7%8E%A9%E7%8E%A9%E6%B8%B8%E6%88%8F/"},{"name":"技术记录","slug":"技术记录","link":"/categories/%E6%8A%80%E6%9C%AF%E8%AE%B0%E5%BD%95/"},{"name":"折腾之旅","slug":"折腾之旅","link":"/categories/%E6%8A%98%E8%85%BE%E4%B9%8B%E6%97%85/"}]}